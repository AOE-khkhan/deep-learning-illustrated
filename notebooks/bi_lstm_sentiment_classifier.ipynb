{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM Sentiment Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we use a *bidirectional* LSTM to classify IMDB movie reviews by their sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, SpatialDropout1D, LSTM\n",
    "from keras.layers.wrappers import Bidirectional # new! \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output directory name:\n",
    "output_dir = 'model_output/biLSTM'\n",
    "\n",
    "# training:\n",
    "epochs = 6\n",
    "batch_size = 128\n",
    "\n",
    "# vector-space embedding: \n",
    "n_dim = 64 \n",
    "n_unique_words = 10000 \n",
    "max_review_length = 200 # doubled!\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2 \n",
    "\n",
    "# LSTM layer architecture:\n",
    "n_lstm = 256 \n",
    "drop_lstm = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = imdb.load_data(num_words=n_unique_words) # removed n_words_to_skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length)) \n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(Bidirectional(LSTM(n_lstm, dropout=drop_lstm)))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 64)           640000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 200, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 512)               657408    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 1,297,921\n",
      "Trainable params: 1,297,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM layer parameters double due to both reading directions\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/6\n",
      "25000/25000 [==============================] - 157s 6ms/step - loss: 0.5720 - acc: 0.6936 - val_loss: 0.3837 - val_acc: 0.8401\n",
      "Epoch 2/6\n",
      "25000/25000 [==============================] - 156s 6ms/step - loss: 0.3675 - acc: 0.8438 - val_loss: 0.3456 - val_acc: 0.8535\n",
      "Epoch 3/6\n",
      "25000/25000 [==============================] - 155s 6ms/step - loss: 0.2764 - acc: 0.8923 - val_loss: 0.3584 - val_acc: 0.8448\n",
      "Epoch 4/6\n",
      "25000/25000 [==============================] - 155s 6ms/step - loss: 0.2223 - acc: 0.9166 - val_loss: 0.3308 - val_acc: 0.8604\n",
      "Epoch 5/6\n",
      "25000/25000 [==============================] - 155s 6ms/step - loss: 0.1814 - acc: 0.9333 - val_loss: 0.3846 - val_acc: 0.8546\n",
      "Epoch 6/6\n",
      "25000/25000 [==============================] - 155s 6ms/step - loss: 0.1526 - acc: 0.9450 - val_loss: 0.3855 - val_acc: 0.8649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f57b978f358>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - we see 87.0% validation accuracy in epoch 2\n",
    "# - with this toy dataset, the complex interplay of words over long sentence segments, won't be learned much\n",
    "# - so our CNN picking up location-invariant segments of two to four words that predict review sentiment\n",
    "# - these are simpler and so easier to learn from the data\n",
    "# - CNN therefore outperforms on the IMDB data set\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.06.hdf5\") # zero-indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict_proba(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f57b027f630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'93.63'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:0.2f}\".format(roc_auc_score(y_valid, y_hat)*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
