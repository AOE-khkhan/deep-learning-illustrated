{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning in Keras\n",
    "\n",
    "In this notebook, we'll cover how to load a pre-trained model (in this case, VGGNet19) and finetune it for a new task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the pre-trained VGG19 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = VGG19(include_top=False,\n",
    "              weights='imagenet',\n",
    "              input_shape=(224,224,3),\n",
    "              pooling=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freeze the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in vgg19.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add custom classification layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(vgg19)\n",
    "model.add(Flatten(name='flattened'))\n",
    "model.add(Dropout(0.5, name='dropout'))\n",
    "model.add(Dense(2, activation='softmax', name='predictions'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is available for download [here](https://www.kaggle.com/dansbecker/hot-dog-not-hot-dog/home). You should download the zipfile and extract the contents into a folder called `hot-dog-not-hot-dog` in the main `notebooks` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                   data_format='channels_last',\n",
    "                                   rotation_range=30,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='reflect')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                  data_format='channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 498 images belonging to 2 classes.\n",
      "Found 500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(directory='./hot-dog-not-hot-dog/train',\n",
    "                                                     target_size=(224, 224),\n",
    "                                                     classes=['hot_dog','not_hot_dog'],\n",
    "                                                     class_mode='categorical',\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     shuffle=True,\n",
    "                                                     seed=42)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(directory='./hot-dog-not-hot-dog/test',\n",
    "                                                     target_size=(224, 224),\n",
    "                                                     classes=['hot_dog','not_hot_dog'],\n",
    "                                                     class_mode='categorical',\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     shuffle=True,\n",
    "                                                     seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "15/15 [==============================] - 6s - loss: 1.2048 - acc: 0.5312 - val_loss: 0.5210 - val_acc: 0.7438\n",
      "Epoch 2/40\n",
      "15/15 [==============================] - 4s - loss: 0.6471 - acc: 0.6810 - val_loss: 0.4636 - val_acc: 0.7778\n",
      "Epoch 3/40\n",
      "15/15 [==============================] - 4s - loss: 0.5018 - acc: 0.7565 - val_loss: 0.4323 - val_acc: 0.7970\n",
      "Epoch 4/40\n",
      "15/15 [==============================] - 4s - loss: 0.4211 - acc: 0.8093 - val_loss: 0.4886 - val_acc: 0.7607\n",
      "Epoch 5/40\n",
      "15/15 [==============================] - 4s - loss: 0.4173 - acc: 0.8290 - val_loss: 0.4889 - val_acc: 0.7585\n",
      "Epoch 6/40\n",
      "15/15 [==============================] - 4s - loss: 0.3307 - acc: 0.8493 - val_loss: 0.4242 - val_acc: 0.8034\n",
      "Epoch 7/40\n",
      "15/15 [==============================] - 4s - loss: 0.3520 - acc: 0.8264 - val_loss: 0.5458 - val_acc: 0.7286\n",
      "Epoch 8/40\n",
      "15/15 [==============================] - 4s - loss: 0.2988 - acc: 0.8660 - val_loss: 0.4453 - val_acc: 0.7875\n",
      "Epoch 9/40\n",
      "15/15 [==============================] - 4s - loss: 0.3122 - acc: 0.8565 - val_loss: 0.4771 - val_acc: 0.7885\n",
      "Epoch 10/40\n",
      "15/15 [==============================] - 4s - loss: 0.2927 - acc: 0.8603 - val_loss: 0.4703 - val_acc: 0.7863\n",
      "Epoch 11/40\n",
      "15/15 [==============================] - 4s - loss: 0.2999 - acc: 0.8472 - val_loss: 0.6080 - val_acc: 0.7564\n",
      "Epoch 12/40\n",
      "15/15 [==============================] - 4s - loss: 0.2894 - acc: 0.8812 - val_loss: 0.5708 - val_acc: 0.7650\n",
      "Epoch 13/40\n",
      "15/15 [==============================] - 4s - loss: 0.2612 - acc: 0.9040 - val_loss: 0.4684 - val_acc: 0.7949\n",
      "Epoch 14/40\n",
      "15/15 [==============================] - 4s - loss: 0.2058 - acc: 0.9030 - val_loss: 0.5537 - val_acc: 0.7585\n",
      "Epoch 15/40\n",
      "15/15 [==============================] - 4s - loss: 0.2250 - acc: 0.9051 - val_loss: 0.4796 - val_acc: 0.7927\n",
      "Epoch 16/40\n",
      "15/15 [==============================] - 4s - loss: 0.2586 - acc: 0.8806 - val_loss: 0.8461 - val_acc: 0.7030\n",
      "Epoch 17/40\n",
      "15/15 [==============================] - 4s - loss: 0.2358 - acc: 0.8979 - val_loss: 0.4201 - val_acc: 0.8141\n",
      "Epoch 18/40\n",
      "15/15 [==============================] - 4s - loss: 0.1736 - acc: 0.9254 - val_loss: 0.4664 - val_acc: 0.8098\n",
      "Epoch 19/40\n",
      "15/15 [==============================] - 4s - loss: 0.1675 - acc: 0.9186 - val_loss: 0.4765 - val_acc: 0.8120\n",
      "Epoch 20/40\n",
      "15/15 [==============================] - 4s - loss: 0.2099 - acc: 0.9129 - val_loss: 0.5746 - val_acc: 0.7714\n",
      "Epoch 21/40\n",
      "15/15 [==============================] - 4s - loss: 0.1732 - acc: 0.9395 - val_loss: 0.5248 - val_acc: 0.7842\n",
      "Epoch 22/40\n",
      "15/15 [==============================] - 4s - loss: 0.2009 - acc: 0.9188 - val_loss: 0.4830 - val_acc: 0.7970\n",
      "Epoch 23/40\n",
      "15/15 [==============================] - 4s - loss: 0.2207 - acc: 0.9114 - val_loss: 0.4949 - val_acc: 0.7885\n",
      "Epoch 24/40\n",
      "15/15 [==============================] - 4s - loss: 0.1195 - acc: 0.9645 - val_loss: 0.5627 - val_acc: 0.7927\n",
      "Epoch 25/40\n",
      "15/15 [==============================] - 4s - loss: 0.1321 - acc: 0.9583 - val_loss: 0.5422 - val_acc: 0.7778\n",
      "Epoch 26/40\n",
      "15/15 [==============================] - 4s - loss: 0.1446 - acc: 0.9442 - val_loss: 0.5713 - val_acc: 0.7799\n",
      "Epoch 27/40\n",
      "15/15 [==============================] - 4s - loss: 0.1805 - acc: 0.9275 - val_loss: 0.5167 - val_acc: 0.7799\n",
      "Epoch 28/40\n",
      "15/15 [==============================] - 4s - loss: 0.1467 - acc: 0.9421 - val_loss: 0.4928 - val_acc: 0.7799\n",
      "Epoch 29/40\n",
      "15/15 [==============================] - 4s - loss: 0.1225 - acc: 0.9562 - val_loss: 0.5552 - val_acc: 0.7735\n",
      "Epoch 30/40\n",
      "15/15 [==============================] - 4s - loss: 0.1308 - acc: 0.9645 - val_loss: 0.5012 - val_acc: 0.8056\n",
      "Epoch 31/40\n",
      "15/15 [==============================] - 4s - loss: 0.1389 - acc: 0.9505 - val_loss: 0.6061 - val_acc: 0.7628\n",
      "Epoch 32/40\n",
      "15/15 [==============================] - 4s - loss: 0.1699 - acc: 0.9391 - val_loss: 0.5284 - val_acc: 0.7842\n",
      "Epoch 33/40\n",
      "15/15 [==============================] - 4s - loss: 0.1256 - acc: 0.9437 - val_loss: 0.4949 - val_acc: 0.8098\n",
      "Epoch 34/40\n",
      "15/15 [==============================] - 4s - loss: 0.1287 - acc: 0.9562 - val_loss: 0.6890 - val_acc: 0.7628\n",
      "Epoch 35/40\n",
      "15/15 [==============================] - 4s - loss: 0.1283 - acc: 0.9442 - val_loss: 0.5570 - val_acc: 0.7991\n",
      "Epoch 36/40\n",
      "15/15 [==============================] - 4s - loss: 0.0839 - acc: 0.9693 - val_loss: 0.5407 - val_acc: 0.7885\n",
      "Epoch 37/40\n",
      "15/15 [==============================] - 4s - loss: 0.1200 - acc: 0.9541 - val_loss: 0.6003 - val_acc: 0.7991\n",
      "Epoch 38/40\n",
      "15/15 [==============================] - 4s - loss: 0.1473 - acc: 0.9400 - val_loss: 0.6881 - val_acc: 0.7714\n",
      "Epoch 39/40\n",
      "15/15 [==============================] - 4s - loss: 0.1392 - acc: 0.9380 - val_loss: 0.5737 - val_acc: 0.7906\n",
      "Epoch 40/40\n",
      "15/15 [==============================] - 4s - loss: 0.1171 - acc: 0.9615 - val_loss: 0.6710 - val_acc: 0.7714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd3e0422b70>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=15, epochs=40, validation_data=test_generator, validation_steps=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
